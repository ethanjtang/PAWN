"""
This file reads in the two training and validation pval data files produced by pval_train_val_split.py.
It uses this data to train different configs of the simple MLP and MLP+CNN piece value predictor models.

Simple MLP models take a piece-type one-hot vector (10d, excluding kings) + location information (2d or 4d based on if quadratic location is included)
and return a value from [-inf,+inf] predicting a piece's value.

Augmented MLP+CNN operate similarly, but also append an additional M dimension vector containing an intermediate representation
of the chess position. This intermediate representation is generated by some config of a CNN autoencoder
which minimizes the error in reconstructing an encoded position via decoding.
It then takes this M-dim position representation + N-dim piece type and location information identical to the
simple MLP as input, and returns a value from [-inf,+inf] predicting a piece's value.

Important things to note about the architecture:
1. CNN position encoders have graduated dropout per layer (larger dropout for larger layers)
2. We train 3 MLPs, 1 is a recreation from Gupta's 2023 paper while the other two scale his architecture up
3. We use relatively large patience for pval predictors (50) vs. position autoencoders (10) since
   we don't need extremely accurate position encodings (we just want to capture their "essense").
4. Position representations do not include state information including side to move, castling rights, etc.
   This can be potentially explored in the future but likely won't add a ton of accuracy to predictions
   because they are a relatively small factor compared to the relationships between all pieces.
5. We swapped from MSE to Huber Loss for training to ensure our model predicts both normal (average) and 
   extreme piece values accurately.
6. M=512 for CNN encoded positions performed the best in our preliminary tests with M={128,256,512}
   so we use it for all of our final tests.
7. When running this code yourself, you may need to load the parquet file in chunks. we had access to
   supercompute via Sol so loading the entire 12m+ row DF in memory was fine for us.
8. DO NOT save position embeddings to the rows containing piece value data entries directly! This
   causes an explosion in file size (40+ GB).

Input:
- Reads from train.parquet and val.parquet (produced by pval_train_val_split.py)
- Columns: game_id, fen, move_number, side_to_move, eco_code, opening,
           white_material, black_material, piece_type, rank, file,
           original_eval, eval_without_piece, piece_value

Output:
- output/cnn_pos_*_encoder.pth - CNN position encoder models for each configuration
- output/mlp*_model.pth - MLP baseline pval prediction models
- output/cnn_pos_*_pval_*_model.pth - MLP+CNN piece value predictor models
- output/all_models_metrics.json - Training and evaluation metric data

Usage:
    python train_all_models.py

"""

# imports
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from pathlib import Path
import json
import time
import os
import sys
import chess
from tqdm import tqdm
import pickle
import gc

# ========================================
# GENERAL CONFIG
# ========================================

# Input/output file paths
TRAINING_PARQUET = "train.parquet"
VALIDATION_PARQUET = "val.parquet"
OUTPUT_DIR = "output" # output files placed in this dir

# Chunk size (in rows) for reading large parquet files 
CHUNK_SIZE = 10000  # Set this or you will get many memory errors!

# Piece type to channel mapping for CNN
# White pieces are uppercase, Black pieces are lowercase
PIECE_CHANNELS = {
    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,
    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11
}

# CNN autoencoder architecture config
CNN_EMBEDDING_DIMS = [512] # We tested d=128,256 but d=512 performs the best (likely because there is more info in a larger embedding of a position)
CNN_LAYER_DEPTHS = [4, 6, 8]

# Augmented (MLP+CNN) pval predictor hidden layer variants
CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS = {
    3: [256, 128, 64],
    4: [512, 256, 128, 64],
    5: [1024, 512, 256, 128, 64]
}

# Graduated dropout per layer for augmented MLP+CNN pval predictors
# Higher dropout on wider (earlier) layers, lower on narrower (later) layers
CNN_PIECEVAL_DROPOUT_RATES = {
    3: [0.3, 0.2, 0.1],
    4: [0.35, 0.25, 0.15, 0.1],
    5: [0.4, 0.3, 0.2, 0.15, 0.1]
}

# Config for CNN autoencoder to gen intermediate position representations
CNN_POSITION_CONFIG = {
    'batch_size': 1024,
    'lr': 0.001,
    'max_epochs': 10000,
    'patience': 50 # this is probably too high but oh well!
}

# Config for simple MLP pval predictor (MLP #1 and MLP #2) with 3 hidden layers
MLP_CONFIG = {
    'batch_size': 1024,
    'lr': 0.001,
    'weight_decay': 1e-4,
    'dropout': 0.2,
    'hidden_sizes': [128, 64, 32],
    'patience': 50
}

# Original baseline from Gupta 2023, simple MLP with 2 hidden layers
CHESSABLE_RESEARCH_2023_CONFIG = {
    'batch_size': 1024,
    'lr': 0.001,
    'weight_decay': 1e-4,
    'dropout': 0.2,
    'hidden_sizes': [64, 32],
    'patience': 50
}

# Config for augmented MLP+CNN pval predictor: MLP pval prediction part
CNN_PIECEVAL_CONFIG = {
    'batch_size': 1024,
    'lr': 0.001,
    'weight_decay': 1e-4,
    'patience': 50
}

# Use Huber loss delta instead of MSE during training
# delta=1.0 -> errors < 1 stdev are treated as MSE, larger errors as MAE
# important because some piece values will be very extreme (up to 5x initial value)
# and we want the model to be good at predicting both standard and extreme piece values
HUBER_DELTA = 1.0


# ========================================
# CNN POSITION ENCODER (AUTOENCODER)
# ========================================

# Encoder (create intermediate position representation)
class ChessCNNEncoder(nn.Module):
    """CNN encoder that produces variable-dimensional embeddings with configurable depth"""
    def __init__(self, embedding_dim=512, num_layers=4):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.num_layers = num_layers

        layers = []
        in_channels = 12

        # Determine channel progression based on number of layers
        if num_layers == 4:
            channels = [32, 64, embedding_dim, embedding_dim]
        elif num_layers == 6:
            channels = [32, 64, 128, embedding_dim, embedding_dim, embedding_dim]
        elif num_layers == 8:
            channels = [32, 64, 128, 256, embedding_dim, embedding_dim, embedding_dim, embedding_dim]
        else:
            raise ValueError(f"Unsupported num_layers: {num_layers}. Must be 4, 6, or 8.")

        # Build convolutional layers
        for out_channels in channels:
            layers.extend([
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.ReLU(),
                nn.BatchNorm2d(out_channels)
            ])
            in_channels = out_channels

        # Add adaptive pooling at the end
        layers.append(nn.AdaptiveAvgPool2d(1))

        self.conv = nn.Sequential(*layers)

    def forward(self, board):
        """
        Args:
            board: Tensor of shape (batch, 12, 8, 8)
        Returns:
            Tensor of shape (batch, embedding_dim)
        """
        x = self.conv(board)
        return x.view(board.size(0), -1)

# Decoder (reconstruct original position from intermediate representation)
class ChessCNNDecoder(nn.Module):
    """CNN decoder that reconstructs position from embedding with configurable depth"""
    def __init__(self, embedding_dim=512, num_layers=4):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.num_layers = num_layers

        # Project embedding to spatial dimensions
        self.project = nn.Linear(embedding_dim, embedding_dim * 8 * 8)

        # Determine channel progression based on number of layers (reverse of encoder)
        if num_layers == 4:
            channels = [embedding_dim, 64, 32, 12]
        elif num_layers == 6:
            channels = [embedding_dim, embedding_dim, 128, 64, 32, 12]
        elif num_layers == 8:
            channels = [embedding_dim, embedding_dim, 256, 128, 64, 32, 32, 12]
        else:
            raise ValueError(f"Unsupported num_layers: {num_layers}. Must be 4, 6, or 8.")

        # Build deconvolutional layers
        layers = []
        in_channels = embedding_dim
        for i, out_channels in enumerate(channels):
            layers.append(nn.Conv2d(in_channels, out_channels, 3, padding=1))
            # Use Sigmoid activation on final layer, ReLU + BatchNorm on others
            if i == len(channels) - 1:
                layers.append(nn.Sigmoid())
            else:
                layers.extend([nn.ReLU(), nn.BatchNorm2d(out_channels)])
            in_channels = out_channels

        self.deconv = nn.Sequential(*layers)

    def forward(self, embedding):
        """
        Args:
            embedding: Tensor of shape (batch, embedding_dim)
        Returns:
            Tensor of shape (batch, 12, 8, 8)
        """
        x = self.project(embedding)
        x = x.view(-1, self.embedding_dim, 8, 8)
        return self.deconv(x)

# Combine encoder and decoder for full autoencoder
class ChessAutoencoder(nn.Module):
    """Full autoencoder model with configurable embedding dimension and depth"""
    def __init__(self, embedding_dim=128, num_layers=4):
        super().__init__()
        self.encoder = ChessCNNEncoder(embedding_dim, num_layers)
        self.decoder = ChessCNNDecoder(embedding_dim, num_layers)
        self.embedding_dim = embedding_dim
        self.num_layers = num_layers

    def forward(self, board):
        embedding = self.encoder(board)
        reconstruction = self.decoder(embedding)
        return reconstruction, embedding

# Helper function to convert FEN to 12x8x8 board tensor
# 12 for each piece type (White/Black), 8x8 for squares on the chess board
# We do not include state information (but this is an avenue for further tests)
def fen_to_board_tensor(fen):
    """Convert FEN to 12x8x8 board tensor"""
    board = chess.Board(fen)
    board_tensor = np.zeros((8, 8, 12), dtype=np.float32)

    # Mark piece locations for each square on the respective dimension
    for square in chess.SQUARES:
        piece = board.piece_at(square)
        if piece:
            rank = chess.square_rank(square)
            file = chess.square_file(square)
            channel = PIECE_CHANNELS[piece.symbol()]
            board_tensor[rank, file, channel] = 1.0

    # Transpose to (12, 8, 8) for PyTorch
    return np.transpose(board_tensor, (2, 0, 1))

# Object to store chess positions
class ChessPositionDataset(Dataset):
    """Dataset for chess positions (autoencoder training)"""
    def __init__(self, fens):
        self.fens = fens

    def __len__(self):
        return len(self.fens)

    def __getitem__(self, idx):
        fen = self.fens[idx]
        board_tensor = fen_to_board_tensor(fen)
        return torch.from_numpy(board_tensor)

# Helper class to stop training in case of overfitting
class EarlyStopping:
    """Early stopping to prevent overfitting"""
    def __init__(self, patience=10, min_delta=0.0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.should_stop = False

    # Stop if val-loss does not improve after patience=10 epohs
    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.should_stop = True
        return self.should_stop

# Function to train CNN position autoencoder
def train_cnn_position_encoder(unique_fens, config, output_dir, embedding_dim=512, num_layers=4, model_name="cnn"):
    """Train CNN position encoder using autoencoder approach"""
    print(f"\n{'='*60}")
    print(f"TRAINING CNN POSITION ENCODER: {model_name}")
    print(f"{'='*60}")
    print(f"Embedding dimension: {embedding_dim}")
    print(f"Number of layers: {num_layers}")
    print(f"Unique positions: {len(unique_fens):,}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print(f"Max epochs: {config['max_epochs']}")
    print(f"Early stopping patience: {config['patience']}")
    print(f"{'='*60}\n")

    start_time = time.time()

    # Split data into 80/20 train/val with random_state=42
    train_fens, val_fens = train_test_split(unique_fens, test_size=0.2, random_state=42)
    print(f"Training positions: {len(train_fens):,}")
    print(f"Validation positions: {len(val_fens):,}\n")

    train_dataset = ChessPositionDataset(train_fens)
    val_dataset = ChessPositionDataset(val_fens)

    # Load training and validation data
    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],
                             shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], num_workers=0)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}\n")

    model = ChessAutoencoder(embedding_dim=embedding_dim, num_layers=num_layers).to(device)
    optimizer = optim.Adam(model.parameters(), lr=config['lr'])
    criterion = nn.BCELoss()

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5
    )

    early_stopping = EarlyStopping(patience=config['patience'])
    best_val_loss = float('inf')
    best_epoch = 0

    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True, parents=True)

    # Training loop
    for epoch in range(1, config['max_epochs'] + 1):
        epoch_start = time.time()

        # Train the CNN position autoencoder on train set
        model.train()
        train_loss = 0
        for board in train_loader:
            board = board.to(device)
            optimizer.zero_grad()
            reconstruction, _ = model(board)
            loss = criterion(reconstruction, board)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validate against val set
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for board in val_loader:
                board = board.to(device)
                reconstruction, _ = model(board)
                loss = criterion(reconstruction, board)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        epoch_time = time.time() - epoch_start

        # Save best model (if val_loss is less than the previous best model)
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_epoch = epoch
            torch.save(model.state_dict(), output_path / f"best_{model_name}_autoencoder_checkpoint.pth")
            torch.save(model.encoder.state_dict(), output_path / f"best_{model_name}_encoder.pth")

        # Print out epoch information
        print(f"Epoch {epoch:3d}/{config['max_epochs']} ({epoch_time:.1f}s) - "
              f"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | "
              f"Best: {best_val_loss:.6f} (epoch {best_epoch})")

        scheduler.step(val_loss)

        # Check if we need to stop in case of overfitting
        if early_stopping(val_loss):
            print(f"\nEarly stopping triggered after {epoch} epochs")
            print(f"Best model was at epoch {best_epoch}\n")
            break

    # Load best model
    model.load_state_dict(torch.load(output_path / f"best_{model_name}_autoencoder_checkpoint.pth"))

    elapsed_time = time.time() - start_time

    # Save final position encoder
    torch.save(model.encoder.state_dict(), output_path / f"{model_name}_encoder.pth")

    metadata = {
        'model_type': 'cnn_position_encoder',
        'model_name': model_name,
        'embedding_dim': embedding_dim,
        'num_layers': num_layers,
        'unique_positions': len(unique_fens),
        'training_positions': len(train_fens),
        'validation_positions': len(val_fens),
        'best_epoch': best_epoch,
        'best_val_loss': float(best_val_loss),
        'training_time_seconds': elapsed_time,
        'config': config
    }

    print(f"\n{'='*60}")
    print("CNN POSITION ENCODER TRAINING COMPLETE")
    print(f"{'='*60}")
    print(f"Training time: {elapsed_time/60:.1f} minutes")
    print(f"Best epoch: {best_epoch}")
    print(f"Best val loss: {best_val_loss:.6f}")
    print(f"{'='*60}\n")

    return model.encoder, metadata


# ========================================
# SIMPLE MLP PIECE VALUE PREDICTOR
# ========================================

class SimplePieceValueMLP(nn.Module):
    """
    Simple MLP for piece value prediction.
    """
    def __init__(self, input_dim=12, hidden_sizes=[128, 64, 32], dropout=0.3):
        super().__init__()

        layers = []
        input_size = input_dim

        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(input_size, hidden_size))
            layers.append(nn.BatchNorm1d(hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout))
            input_size = hidden_size

        layers.append(nn.Linear(input_size, 1))
        self.mlp = nn.Sequential(*layers)

    def forward(self, x):
        return self.mlp(x)

# Object to store values in pval dataset
class SimplePieceValueDataset(Dataset):
    """Dataset for simple MLP piece value prediction"""
    def __init__(self, df, include_quadratic=False):
        # Extract features
        piece_types = ['p', 'P', 'n', 'N', 'b', 'B', 'r', 'R', 'q', 'Q']
        piece_type_onehot = np.zeros((len(df), len(piece_types)), dtype=np.float32)

        # Convert piece type to one-hot vector
        for i, piece_type in enumerate(piece_types):
            piece_type_onehot[:, i] = (df['piece_type'] == piece_type).astype(np.float32)

        # Normalize rank/files for each piece value entry
        ranks = (df['rank'].values / 7.0).astype(np.float32)
        files = (df['file'].values / 7.0).astype(np.float32)

        # Add normalized rank^2 and file^2 for each entry if training requires it
        if include_quadratic:
            self.features = np.concatenate([
                piece_type_onehot,
                ranks.reshape(-1, 1),
                files.reshape(-1, 1),
                (ranks**2).reshape(-1, 1),
                (files**2).reshape(-1, 1)
            ], axis=1).astype(np.float32)
        else:
            self.features = np.concatenate([
                piece_type_onehot,
                ranks.reshape(-1, 1),
                files.reshape(-1, 1)
            ], axis=1).astype(np.float32)

        self.values = df['piece_value'].values.astype(np.float32)

    def __len__(self):
        return len(self.values)

    def __getitem__(self, idx):
        return (
            torch.from_numpy(self.features[idx]),
            torch.tensor([self.values[idx]], dtype=torch.float32)
        )

# Helper function to train simple MLP model
def train_mlp_model(train_df, val_df, config, include_quadratic, model_name, norm_params, output_dir):
    """Train simple MLP piece value prediction model"""
    input_dim = 14 if include_quadratic else 12
    mlp_version = "MLP #2 (14-dim)" if include_quadratic else "MLP #1 (12-dim)"

    print(f"\n{'='*60}")
    print(f"TRAINING {mlp_version}")
    print(f"{'='*60}")
    print(f"Training samples: {len(train_df):,}")
    print(f"Validation samples: {len(val_df):,}")
    print(f"Input dimensions: {input_dim}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print(f"Weight decay: {config['weight_decay']}")
    print(f"Dropout: {config['dropout']}")
    print(f"Hidden sizes: {config['hidden_sizes']}")
    print(f"Loss function: HuberLoss(delta={HUBER_DELTA})")
    print(f"Normalization: Standardization (mean/std)")
    print(f"{'='*60}\n")

    start_time = time.time()

    # Create and load train/val piece value dataset
    train_dataset = SimplePieceValueDataset(train_df, include_quadratic=include_quadratic)
    val_dataset = SimplePieceValueDataset(val_df, include_quadratic=include_quadratic)

    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],
                             shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], num_workers=0)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}\n")

    # Initialize the model
    model = SimplePieceValueMLP(
        input_dim=input_dim,
        hidden_sizes=config['hidden_sizes'],
        dropout=config['dropout']
    ).to(device)

    # pick garen
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )

    # Huber Loss instead of MSE
    criterion = nn.HuberLoss(delta=HUBER_DELTA)

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5
    )

    # Set other important variables
    early_stopping = EarlyStopping(patience=config['patience'])
    best_val_loss = float('inf')
    best_epoch = 0

    output_path = Path(output_dir)

    epoch = 0

    # Training loop
    while True:
        epoch += 1
        epoch_start = time.time()

        # Train the model on train set
        model.train()
        train_loss = 0
        for features, target in train_loader:
            features, target = features.to(device), target.to(device)
            optimizer.zero_grad()
            pred = model(features)
            loss = criterion(pred, target)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validate the model on val set
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for features, target in val_loader:
                features, target = features.to(device), target.to(device)
                pred = model(features)
                loss = criterion(pred, target)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        epoch_time = time.time() - epoch_start

        # Denormalize using standardization params (mean/std)
        # This is a rough approximation, we are training using Huber Loss (~MSE for <100cp, ~MAE for >100cp) while final results use strictly MAE!
        approx_error_std = np.sqrt(val_loss * 2)  # rough approximation
        approx_error_cp = approx_error_std * norm_params['std']

        # Save the best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_epoch = epoch
            torch.save(model.state_dict(), output_path / f"best_{model_name}_checkpoint.pth")

        # Print training loop info
        print(f"Epoch {epoch:3d} ({epoch_time:.1f}s) - "
              f"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | "
              f"~{approx_error_cp:.2f} cp | "
              f"Best: {best_val_loss:.6f} (epoch {best_epoch})")

        scheduler.step(val_loss)

        # Stop training if overfitting
        if early_stopping(val_loss):
            print(f"\nEarly stopping triggered after {epoch} epochs")
            print(f"Best model was at epoch {best_epoch}\n")
            break

    # Load best model
    model.load_state_dict(torch.load(output_path / f"best_{model_name}_checkpoint.pth"))

    elapsed_time = time.time() - start_time

    # Save final model
    torch.save(model.state_dict(), output_path / f"{model_name}_model.pth")

    metadata = {
        'model_type': model_name,
        'mlp_version': mlp_version,
        'training_samples': len(train_df),
        'validation_samples': len(val_df),
        'best_epoch': best_epoch,
        'best_val_loss': float(best_val_loss),
        'training_time_seconds': elapsed_time,
        'config': config,
        'input_dim': input_dim,
        'improvements': ['AdamW', 'weight_decay', 'HuberLoss', 'BatchNorm1d', 'standardization']
    }

    print(f"\n{'='*60}")
    print(f"{mlp_version} TRAINING COMPLETE")
    print(f"{'='*60}")
    print(f"Training time: {elapsed_time/60:.1f} minutes")
    print(f"Best epoch: {best_epoch}")
    print(f"Best val loss: {best_val_loss:.6f}")
    print(f"{'='*60}\n")

    return model, metadata

# Helper function to evalaute simple MLP models
def evaluate_mlp_model(model, df, include_quadratic, norm_params, device):
    """
    Evaluate MLP model on a dataset and return MAE error in centipawns.
    """
    dataset = SimplePieceValueDataset(df, include_quadratic=include_quadratic)
    loader = DataLoader(dataset, batch_size=1024, num_workers=0)

    model.eval()
    total_abs_error = 0.0
    total_samples = 0

    with torch.no_grad():
        for features, target in loader:
            features, target = features.to(device), target.to(device)
            pred = model(features)
            # Compute MAE in standardized space
            abs_error = torch.abs(pred - target).sum().item()
            total_abs_error += abs_error
            total_samples += target.size(0)

    # MAE in standardized space -> centipawns
    mae_standardized = total_abs_error / total_samples
    mae_cp = mae_standardized * norm_params['std']

    return float(mae_cp)

# ========================================
# AUGMENTED MLP+CNN PIECE VALUE PREDICTOR
# ========================================

class CNNPieceValuePredictor(nn.Module):
    """
    MLP that takes CNN embedding + piece location to predict piece value.
    """
    def __init__(self, embedding_dim=128, hidden_sizes=[256, 128, 64],
                 dropout=0.3, dropout_rates=None):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.hidden_sizes = hidden_sizes

        # Input: embedding_dim + 14 (piece location features)
        # I am pretty sure the order doesn't matter but putting piece location features makes more sense.
        # I blame Claude, this isn't my fault.
        # Other mistakes (that I had to fix) by Claude include:
        # - not capping piece type values correctly forcing me to rerun tests
        # - gathering piece value data using a multiprocessing Queue (and causing many race conditions)
        input_size = embedding_dim + 14

        # Build piece value predictor MLP layers dynamically based on hidden_sizes
        layers = []
        current_size = input_size

        for i, hidden_size in enumerate(hidden_sizes):
            layers.append(nn.Linear(current_size, hidden_size))
            layers.append(nn.BatchNorm1d(hidden_size))
            layers.append(nn.ReLU())
            # Use custom per-layer dropout rates (decreasing with decreasing layer size)
            if dropout_rates is not None and i < len(dropout_rates):
                layers.append(nn.Dropout(dropout_rates[i]))
            else:
                layers.append(nn.Dropout(dropout))
            current_size = hidden_size

        # Output layer (no activation - standardized targets are unbounded)
        # This allows us to just predict some float [-inf,+inf] representing piece value
        layers.append(nn.Linear(current_size, 1))

        self.mlp = nn.Sequential(*layers)

    def forward(self, cnn_embedding, piece_loc):
        x = torch.cat([cnn_embedding, piece_loc], dim=1)
        return self.mlp(x)

# Helper object to store peice value data with special column for CNN-encoded intermediate position representation vectors as embeddings
class CNNPieceValueDataset(Dataset):
    """Dataset for CNN-based piece value prediction"""
    def __init__(self, df, embed_column='cnn_position_embed'):
        # Extract CNN embeddings
        self.cnn_embeddings = np.stack(df[embed_column].values).astype(np.float32)

        # Extract piece location features
        piece_types = ['p', 'P', 'n', 'N', 'b', 'B', 'r', 'R', 'q', 'Q']
        piece_type_onehot = np.zeros((len(df), len(piece_types)), dtype=np.float32)

        # Initialize one-hot vector
        for i, piece_type in enumerate(piece_types):
            piece_type_onehot[:, i] = (df['piece_type'] == piece_type).astype(np.float32)
        
        # Normalize piece rank/file
        ranks = (df['rank'].values / 7.0).astype(np.float32).reshape(-1, 1)
        files = (df['file'].values / 7.0).astype(np.float32).reshape(-1, 1)

        # Also include rank^2 and file^2 (for fun) in piece location vector
        self.piece_locations = np.concatenate([
            piece_type_onehot,
            ranks,
            files,
            ranks**2,
            files**2
        ], axis=1)

        self.values = df['piece_value'].values.astype(np.float32)

    def __len__(self):
        return len(self.values)

    def __getitem__(self, idx):
        return (
            torch.from_numpy(self.cnn_embeddings[idx]),
            torch.from_numpy(self.piece_locations[idx]),
            torch.tensor([self.values[idx]], dtype=torch.float32)
        )

# Helper function to train augmented CNN+MLP piece value predictor
def train_cnn_pieceval_model(train_df, val_df, config, norm_params, output_dir,
                              embedding_dim=512, hidden_sizes=[256, 128, 64],
                              dropout_rates=None, model_name="cnn_pieceval",
                              embed_column='cnn_position_embed'):
    """Train CNN-based piece value prediction model"""
    print(f"\n{'='*60}")
    print(f"TRAINING CNN PIECE VALUE PREDICTOR: {model_name}")
    print(f"{'='*60}")
    print(f"Embedding column: {embed_column}")
    print(f"Embedding dimension: {embedding_dim}")
    print(f"Hidden layer architecture: {hidden_sizes}")
    print(f"Number of hidden layers: {len(hidden_sizes)}")
    print(f"Graduated dropout rates: {dropout_rates}")
    print(f"Training samples: {len(train_df):,}")
    print(f"Validation samples: {len(val_df):,}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print(f"Weight decay: {config['weight_decay']}")
    print(f"Loss function: HuberLoss(delta={HUBER_DELTA})")
    print(f"{'='*60}\n")

    start_time = time.time()

    # Load training and validation dataset
    train_dataset = CNNPieceValueDataset(train_df, embed_column=embed_column)
    val_dataset = CNNPieceValueDataset(val_df, embed_column=embed_column)

    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],
                             shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], num_workers=0)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}\n")

    # Set graduated dropout rates
    model = CNNPieceValuePredictor(
        embedding_dim=embedding_dim,
        hidden_sizes=hidden_sizes,
        dropout_rates=dropout_rates
    ).to(device)

    optimizer = optim.AdamW(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )

    # Use Huber loss for val loss metric
    criterion = nn.HuberLoss(delta=HUBER_DELTA)

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5
    )

    early_stopping = EarlyStopping(patience=config['patience'])
    best_val_loss = float('inf')
    best_epoch = 0

    output_path = Path(output_dir)

    epoch = 0

    # Training loop
    while True:
        epoch += 1
        epoch_start = time.time()

        # Train the model on training data
        model.train()
        train_loss = 0
        for cnn_emb, piece_loc, target in train_loader:
            cnn_emb, piece_loc, target = cnn_emb.to(device), piece_loc.to(device), target.to(device)
            optimizer.zero_grad()
            pred = model(cnn_emb, piece_loc)
            loss = criterion(pred, target)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validate the model on validation data
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for cnn_emb, piece_loc, target in val_loader:
                cnn_emb, piece_loc, target = cnn_emb.to(device), piece_loc.to(device), target.to(device)
                pred = model(cnn_emb, piece_loc)
                loss = criterion(pred, target)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        epoch_time = time.time() - epoch_start

        # Print approximate error in cp for display
        # Our training uses Huber Loss while we do validation in pure MAE
        # so the approximate cp error will appear larger in training loop
        approx_error_std = np.sqrt(val_loss * 2)
        approx_error_cp = approx_error_std * norm_params['std']

        # Save the best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_epoch = epoch
            torch.save(model.state_dict(), output_path / f"best_{model_name}_checkpoint.pth")

        # Print training loop info
        print(f"Epoch {epoch:3d} ({epoch_time:.1f}s) - "
              f"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | "
              f"~{approx_error_cp:.2f} cp | "
              f"Best: {best_val_loss:.6f} (epoch {best_epoch})")

        scheduler.step(val_loss)

        # Stop in case of overfitting
        if early_stopping(val_loss):
            print(f"\nEarly stopping triggered after {epoch} epochs")
            print(f"Best model was at epoch {best_epoch}\n")
            break

    # Load best model
    model.load_state_dict(torch.load(output_path / f"best_{model_name}_checkpoint.pth"))

    elapsed_time = time.time() - start_time

    # Save final model
    torch.save(model.state_dict(), output_path / f"{model_name}_model.pth")

    metadata = {
        'model_type': 'cnn_pieceval',
        'model_name': model_name,
        'embedding_dim': embedding_dim,
        'hidden_sizes': hidden_sizes,
        'dropout_rates': dropout_rates,
        'num_hidden_layers': len(hidden_sizes),
        'training_samples': len(train_df),
        'validation_samples': len(val_df),
        'best_epoch': best_epoch,
        'best_val_loss': float(best_val_loss),
        'training_time_seconds': elapsed_time,
        'config': config,
        'input_features': {
            'cnn_embedding': embedding_dim,
            'piece_location': 14,
            'total': embedding_dim + 14
        },
        'improvements': ['AdamW', 'weight_decay', 'HuberLoss', 'BatchNorm1d',
                         'graduated_dropout', 'standardization']
    }

    # Print training loop confirmation message and return model
    print(f"\n{'='*60}")
    print("CNN PIECE VALUE PREDICTOR TRAINING COMPLETE")
    print(f"{'='*60}")
    print(f"Training time: {elapsed_time/60:.1f} minutes")
    print(f"Best epoch: {best_epoch}")
    print(f"Best val loss: {best_val_loss:.6f}")
    print(f"{'='*60}\n")

    return model, metadata

# Helper function to evaluate augmented MLP+CNN piece value predictor
def evaluate_cnn_pieceval_model(model, df, norm_params, device, embed_column='cnn_position_embed'):
    """
    Evaluate CNN piece value model on a dataset and return MAE in centipawns.
    """
    dataset = CNNPieceValueDataset(df, embed_column=embed_column)
    loader = DataLoader(dataset, batch_size=1024, num_workers=0)

    model.eval()
    total_abs_error = 0.0
    total_samples = 0

    with torch.no_grad():
        for cnn_emb, piece_loc, target in loader:
            cnn_emb, piece_loc, target = cnn_emb.to(device), piece_loc.to(device), target.to(device)
            pred = model(cnn_emb, piece_loc)
            abs_error = torch.abs(pred - target).sum().item()
            total_abs_error += abs_error
            total_samples += target.size(0)

    # MAE in standardized space -> centipawns
    mae_standardized = total_abs_error / total_samples
    mae_cp = mae_standardized * norm_params['std']

    return float(mae_cp)

# ========================================
# CNN-ENCODED INTERMEDIATE POSITION REPRESENTATION EMBEDDING GENERATION
# ========================================

def generate_embeddings_for_fens(fens, encoder, model_name="cnn"):
    """
    Generate CNN embeddings for a list of unique FEN positions.
    Returns a dictionary mapping FEN -> embedding array.
    """
    print(f"\n{'='*60}")
    print(f"GENERATING CNN POSITION EMBEDDINGS: {model_name}")
    print(f"{'='*60}")
    print(f"Unique positions: {len(fens):,}")
    print(f"{'='*60}\n")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    encoder = encoder.to(device)
    encoder.eval()

    # Generate embeddings for unique FENs
    print("Generating embeddings for unique positions...")
    fen_to_embedding = {}

    batch_fens = []
    batch_size = 128 # set to avoid memory errors

    with torch.no_grad():
        for i, fen in enumerate(tqdm(fens, desc="Encoding positions")):
            batch_fens.append(fen)

            if len(batch_fens) >= batch_size or i == len(fens) - 1:
                # Convert batch to tensors
                batch_tensors = torch.stack([
                    torch.from_numpy(fen_to_board_tensor(f)) for f in batch_fens
                ]).to(device)

                # Generate embeddings
                embeddings = encoder(batch_tensors).cpu().numpy()

                # Store in dictionary
                for fen, emb in zip(batch_fens, embeddings):
                    fen_to_embedding[fen] = emb

                batch_fens = []

    print(f"Generated {len(fen_to_embedding):,} embeddings\n")

    return fen_to_embedding


# ========================================
# PIECE VALUE DATAFRAME LOADING (CHUNKED)
# ========================================

# Helper method to load pval DF stored in parquet by chunkt to avoid memory issues
# I have access to supercompute with 256 GB of RAM so this is unnecessary now
def load_parquet_chunked(parquet_file, chunk_size=10000):
    """
    Load large parquet file in chunks and return concatenated DataFrame.
    """
    print(f"Loading {parquet_file} in chunks of {chunk_size:,} rows...")

    # Just load the file as normal (lol)
    df = pd.read_parquet(parquet_file)

    print(f"Loaded {len(df):,} rows\n")
    return df


# ========================================
# MAIN METHOD (RUN THE STUFF)
# ========================================

# The main method
def main():
    # Calculate total models being trained in the loop
    total_models = len(CNN_EMBEDDING_DIMS) * len(CNN_LAYER_DEPTHS) * len(CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS)
    total_models_all = 3 + total_models  # 3 MLPs + CNN models

    print("="*80)
    print(f"CHESS PIECE VALUE PREDICTION: {total_models_all} MODEL VARIANTS")
    print("="*80)
    print(f"Training 3 MLP baselines + {total_models} CNN+MLP-based models")
    print()
    print("Model architectures:")
    print("\nMLP Baselines:")
    print("   - MLP #1 (12-dim input, 3 layers [128,64,32])")
    print("   - MLP #2 (14-dim input with rank/file quadratic, 3 layers [128,64,32])")
    print("   - Recreation of Gupta 2023's MLP (12-dim input, 2 layers [64,32])")
    print(f"\nCNN-based models ({len(CNN_EMBEDDING_DIMS)} embedding_dims x {len(CNN_LAYER_DEPTHS)} encoder_layers x {len(CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS)} pieceval_variants = {total_models} models):")
    # Print out CNN+MLP pval predictor configs
    for emb_dim in CNN_EMBEDDING_DIMS:
        for num_layers in CNN_LAYER_DEPTHS:
            for num_hidden in sorted(CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS.keys()):
                hidden_arch = '-'.join(map(str, CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS[num_hidden]))
                dropout_rates = CNN_PIECEVAL_DROPOUT_RATES[num_hidden]
                print(f"   - CNN pos {emb_dim}d-{num_layers}layer, pval {hidden_arch}, dropout {dropout_rates}")
    print("="*80)

    # Create output directory
    output_dir = Path(OUTPUT_DIR)
    output_dir.mkdir(exist_ok=True, parents=True)

    # ========================================
    # Load pval data and get unique FENs
    # ========================================
    print(f"\n{'='*80}")
    print("STEP 1: LOADING DATA")
    print(f"{'='*80}")

    # Load training and validation DF
    train_df = load_parquet_chunked(TRAINING_PARQUET, CHUNK_SIZE)
    val_df = load_parquet_chunked(VALIDATION_PARQUET, CHUNK_SIZE)

    print("Training dataset statistics:")
    print(f"  Total piece values: {len(train_df):,}")
    print(f"  Unique positions: {train_df['fen'].nunique():,}")
    print(f"  Unique games: {train_df['game_id'].nunique():,}")
    print(f"  Piece value range: [{train_df['piece_value'].min()}, {train_df['piece_value'].max()}]")
    print(f"  Piece value mean: {train_df['piece_value'].mean():.2f}")
    print(f"  Piece value std: {train_df['piece_value'].std():.2f}")

    print("\nValidation dataset statistics:")
    print(f"  Total piece values: {len(val_df):,}")
    print(f"  Unique positions: {val_df['fen'].nunique():,}")
    print(f"  Unique games: {val_df['game_id'].nunique():,}")
    print(f"  Piece value range: [{val_df['piece_value'].min()}, {val_df['piece_value'].max()}]")

    # Verify game-level split integrity
    train_games = set(train_df['game_id'].unique())
    val_games = set(val_df['game_id'].unique())
    game_overlap = train_games & val_games
    if game_overlap:
        print(f"\n  WARNING: {len(game_overlap)} games appear in both train and val sets!")
        print(f"  Consider re-running optimized_create_val_train_splits.py")
    else:
        print(f"\n  Game-level split verified: 0 games overlap between train and val")

    # Get unique FENs for position encoder training (from training set only)
    unique_fens = train_df['fen'].unique().tolist()

    # ========================================
    # Normalize piece values using standardization
    # ========================================
    print(f"\n{'='*80}")
    print("STEP 2: NORMALIZING PIECE VALUES (STANDARDIZATION)")
    print(f"{'='*80}")

    # Use training data to compute normalization parameters
    value_mean = train_df['piece_value'].mean()
    value_std = train_df['piece_value'].std()

    print(f"Training set piece value statistics:")
    print(f"  Mean: {value_mean:.2f} cp")
    print(f"  Std:  {value_std:.2f} cp")
    print(f"  Min:  {train_df['piece_value'].min()} cp")
    print(f"  Max:  {train_df['piece_value'].max()} cp")

    # Standardize both datasets using training statistics
    train_df['piece_value'] = (train_df['piece_value'] - value_mean) / value_std
    val_df['piece_value'] = (val_df['piece_value'] - value_mean) / value_std

    norm_params = {
        'mean': float(value_mean),
        'std': float(value_std),
        'normalization_type': 'standardization'
    }

    # Print normalized data statistics
    print(f"\nNormalized: (value - {value_mean:.2f}) / {value_std:.2f}")
    print(f"New train mean: {train_df['piece_value'].mean():.4f} (should be ~0)")
    print(f"New train std:  {train_df['piece_value'].std():.4f} (should be ~1)\n")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}\n")

    # ========================================
    # Train simple MLP models (baselines)
    # ========================================
    print(f"\n{'='*80}")
    print("STEP 3: TRAINING MLP MODELS (BASELINES)")
    print(f"{'='*80}")

    # Train MLP #1
    mlp1_model, mlp1_metadata = train_mlp_model(
        train_df,
        val_df,
        MLP_CONFIG,
        include_quadratic=False,
        model_name="mlp1",
        norm_params=norm_params,
        output_dir=output_dir
    )

    # Clear GPU memory
    del mlp1_model
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # Train MLP #2
    mlp2_model, mlp2_metadata = train_mlp_model(
        train_df,
        val_df,
        MLP_CONFIG,
        include_quadratic=True,
        model_name="mlp2",
        norm_params=norm_params,
        output_dir=output_dir
    )

    # Clear GPU memory
    del mlp2_model
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # Train Gupta 2023 MLP
    chessable2023_model, chessable2023_metadata = train_mlp_model(
        train_df,
        val_df,
        CHESSABLE_RESEARCH_2023_CONFIG,
        include_quadratic=False,
        model_name="chessable2023",
        norm_params=norm_params,
        output_dir=output_dir
    )

    # Clear GPU memory
    del chessable2023_model
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # ========================================
    # Train CNN position encoders and generate embedding files
    # ========================================
    print(f"\n{'='*80}")
    print(f"STEP 4: TRAINING CNN POSITION ENCODERS & GENERATING EMBEDDINGS")
    print(f"{'='*80}")

    # Get all unique FENs from both training and validation sets
    all_unique_fens = pd.concat([train_df['fen'], val_df['fen']]).unique().tolist()

    # Load original parquet files (we'll add columns to these)
    train_df_original = pd.read_parquet(TRAINING_PARQUET)
    val_df_original = pd.read_parquet(VALIDATION_PARQUET)

    cnn_models_metadata = {}
    encoder_configs = []  # Track all encoder configs for later use

    for embedding_dim in CNN_EMBEDDING_DIMS:
        for num_layers in CNN_LAYER_DEPTHS:
            # Base model name for the CNN position encoder
            encoder_model_name = f"cnn_pos_{embedding_dim}d_{num_layers}layer"
            embed_column_name = f"embed_{embedding_dim}d_{num_layers}layer"

            encoder_configs.append({
                'model_name': encoder_model_name,
                'embed_column': embed_column_name,
                'embedding_dim': embedding_dim,
                'num_layers': num_layers
            })

            # Check if encoder checkpoint already exists
            encoder_checkpoint_path = output_dir / f"{encoder_model_name}_encoder.pth"

            if encoder_checkpoint_path.exists():
                print(f"\n{'='*80}")
                print(f"SKIPPING CNN POSITION ENCODER: {encoder_model_name} (checkpoint exists)")
                print(f"Loading from: {encoder_checkpoint_path}")
                print(f"{'='*80}")

                # Load existing encoder
                encoder = ChessCNNEncoder(embedding_dim=embedding_dim, num_layers=num_layers)
                encoder.load_state_dict(torch.load(encoder_checkpoint_path))

                # Create placeholder metadata for skipped training
                encoder_metadata = {
                    'model_type': 'cnn_position_encoder',
                    'model_name': encoder_model_name,
                    'embedding_dim': embedding_dim,
                    'num_layers': num_layers,
                    'loaded_from_checkpoint': str(encoder_checkpoint_path),
                    'training_skipped': True
                }
            else:
                print(f"\n{'='*80}")
                print(f"TRAINING CNN POSITION ENCODER: {encoder_model_name}")
                print(f"Embedding column name: {embed_column_name}")
                print(f"{'='*80}")

                # Train CNN position encoder
                encoder, encoder_metadata = train_cnn_position_encoder(
                    unique_fens,
                    CNN_POSITION_CONFIG,
                    output_dir,
                    embedding_dim=embedding_dim,
                    num_layers=num_layers,
                    model_name=encoder_model_name
                )

            # Generate embeddings for all unique FENs
            fen_to_embedding = generate_embeddings_for_fens(
                all_unique_fens,
                encoder,
                model_name=encoder_model_name
            )

            # Temporarily add embeddings to training dataframe
            print(f"Adding {embed_column_name} column to training data...")
            train_df_original[embed_column_name] = train_df_original['fen'].map(fen_to_embedding)

            # Temporarily add embeddings to validation dataframe
            print(f"Adding {embed_column_name} column to validation data...")
            val_df_original[embed_column_name] = val_df_original['fen'].map(fen_to_embedding)

            print(f"Embeddings added successfully!\n")

            # Store encoder metadata
            cnn_models_metadata[encoder_model_name] = {
                'encoder': encoder_metadata,
                'embed_column': embed_column_name
            }

            # Clear GPU memory for encoder
            del encoder, fen_to_embedding
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    # Save embeddings to separate lookup files
    # Saving them in the main parquet leads to VERY large files (40 GB+)
    print(f"\n{'='*80}")
    print("SAVING EMBEDDING LOOKUP FILES")
    print(f"{'='*80}")
    print("NOTE: Embeddings stored separately to avoid parquet file bloat")
    print("      (Each 512d embedding x millions of rows = 40GB+ if stored inline)")

    # Save FEN -> embedding mappings as separate pickle files
    for config in encoder_configs:
        embed_column_name = config['embed_column']

        # Create lookup dict efficiently by dropping duplicates first
        train_unique = train_df_original.drop_duplicates(subset='fen')[['fen', embed_column_name]]
        fen_embed_lookup = dict(zip(train_unique['fen'], train_unique[embed_column_name]))

        # Add any val-only FENs
        val_unique = val_df_original.drop_duplicates(subset='fen')[['fen', embed_column_name]]
        for fen, embed in zip(val_unique['fen'], val_unique[embed_column_name]):
            if fen not in fen_embed_lookup:
                fen_embed_lookup[fen] = embed

        # Save as pickle (preserves FEN -> numpy array mapping efficiently)
        embed_file = output_dir / f"{embed_column_name}_lookup.pkl"
        with open(embed_file, 'wb') as f:
            pickle.dump(fen_embed_lookup, f)
        print(f"  Saved {embed_file} ({len(fen_embed_lookup):,} unique FENs)")

        # Remove embedding column from dataframes to keep parquet files small
        train_df_original.drop(columns=[embed_column_name], inplace=True)
        val_df_original.drop(columns=[embed_column_name], inplace=True)

    print()

    # Clean up original dataframes (embeddings now saved to pickle files)
    del train_df_original, val_df_original
    gc.collect()

    # ========================================
    # Train Augmented CNN+MLP Piece Value Predictors
    # ========================================
    print(f"\n{'='*80}")
    print(f"STEP 5: TRAINING {total_models} CNN PIECE VALUE PREDICTORS")
    print(f"{'='*80}")

    model_counter = 0

    for config in encoder_configs:
        encoder_model_name = config['model_name']
        embed_column_name = config['embed_column']
        embedding_dim = config['embedding_dim']
        num_layers = config['num_layers']

        # Load embedding lookup for this encoder
        embed_file = output_dir / f"{embed_column_name}_lookup.pkl"
        print(f"\nLoading embeddings from {embed_file}...")
        with open(embed_file, 'rb') as f:
            fen_to_embedding = pickle.load(f)
        print(f"  Loaded {len(fen_to_embedding):,} FEN -> embedding mappings")

        # Create dataframes with embeddings for this encoder only
        train_df_with_embed = train_df.copy()
        val_df_with_embed = val_df.copy()
        # Add embedding columns
        train_df_with_embed[embed_column_name] = train_df_with_embed['fen'].map(fen_to_embedding)
        val_df_with_embed[embed_column_name] = val_df_with_embed['fen'].map(fen_to_embedding)

        # Train piece value predictors with different hidden layer architectures
        for num_hidden_layers in sorted(CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS.keys()):
            model_counter += 1
            hidden_sizes = CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS[num_hidden_layers] # CNN autoencoder layer count
            dropout_rates = CNN_PIECEVAL_DROPOUT_RATES[num_hidden_layers] # dropout
            hidden_arch_str = '-'.join(map(str, hidden_sizes)) # MLP layer count + nuerons

            # Full model name with piece value predictor architecture
            full_model_name = f"{encoder_model_name}_pval_{hidden_arch_str}"

            print(f"\n{'='*80}")
            print(f"TRAINING MODEL {model_counter}/{total_models}: {full_model_name}")
            print(f"Using embeddings from: {embed_column_name}")
            print(f"Graduated dropout rates: {dropout_rates}")
            print(f"{'='*80}")

            # Train CNN piece value predictor
            pieceval_model, pieceval_metadata = train_cnn_pieceval_model(
                train_df_with_embed,
                val_df_with_embed,
                CNN_PIECEVAL_CONFIG,
                norm_params,
                output_dir,
                embedding_dim=embedding_dim,
                hidden_sizes=hidden_sizes,
                dropout_rates=dropout_rates,
                model_name=full_model_name,
                embed_column=embed_column_name
            )

            # Store metadata
            cnn_models_metadata[full_model_name] = {
                'encoder': cnn_models_metadata[encoder_model_name]['encoder'],
                'embed_column': embed_column_name,
                'pieceval': pieceval_metadata
            }

            # Clear GPU memory
            del pieceval_model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            print(f"\nCompleted training for {full_model_name} ({model_counter}/{total_models})")

        # Clear dataframes and embedding lookup for this encoder before moving to next
        del train_df_with_embed, val_df_with_embed, fen_to_embedding
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # ========================================
    # Evaluate All Models
    # ========================================
    print(f"\n{'='*80}")
    print("STEP 6: EVALUATING ALL MODELS (MAE in centipawns)")
    print(f"{'='*80}")

    evaluation_results = {}

    # Evaluate MLP models
    print("\nEvaluating MLP models...")

    # MLP #1
    mlp1_model_loaded = SimplePieceValueMLP(input_dim=12, hidden_sizes=MLP_CONFIG['hidden_sizes'], dropout=MLP_CONFIG['dropout']).to(device)
    mlp1_model_loaded.load_state_dict(torch.load(output_dir / "mlp1_model.pth"))
    mlp1_train_error = evaluate_mlp_model(mlp1_model_loaded, train_df, include_quadratic=False, norm_params=norm_params, device=device)
    mlp1_val_error = evaluate_mlp_model(mlp1_model_loaded, val_df, include_quadratic=False, norm_params=norm_params, device=device)
    evaluation_results['mlp1'] = {'train_error_cp': mlp1_train_error, 'val_error_cp': mlp1_val_error}
    print(f"  mlp1: Train={mlp1_train_error:.2f} cp, Val={mlp1_val_error:.2f} cp")
    del mlp1_model_loaded

    # MLP #2
    mlp2_model_loaded = SimplePieceValueMLP(input_dim=14, hidden_sizes=MLP_CONFIG['hidden_sizes'], dropout=MLP_CONFIG['dropout']).to(device)
    mlp2_model_loaded.load_state_dict(torch.load(output_dir / "mlp2_model.pth"))
    mlp2_train_error = evaluate_mlp_model(mlp2_model_loaded, train_df, include_quadratic=True, norm_params=norm_params, device=device)
    mlp2_val_error = evaluate_mlp_model(mlp2_model_loaded, val_df, include_quadratic=True, norm_params=norm_params, device=device)
    evaluation_results['mlp2'] = {'train_error_cp': mlp2_train_error, 'val_error_cp': mlp2_val_error}
    print(f"  mlp2: Train={mlp2_train_error:.2f} cp, Val={mlp2_val_error:.2f} cp")
    del mlp2_model_loaded

    # Gupta's 2023 MLP
    chessable_model_loaded = SimplePieceValueMLP(input_dim=12, hidden_sizes=CHESSABLE_RESEARCH_2023_CONFIG['hidden_sizes'], dropout=CHESSABLE_RESEARCH_2023_CONFIG['dropout']).to(device)
    chessable_model_loaded.load_state_dict(torch.load(output_dir / "chessable2023_model.pth"))
    chessable_train_error = evaluate_mlp_model(chessable_model_loaded, train_df, include_quadratic=False, norm_params=norm_params, device=device)
    chessable_val_error = evaluate_mlp_model(chessable_model_loaded, val_df, include_quadratic=False, norm_params=norm_params, device=device)
    evaluation_results['chessable2023'] = {'train_error_cp': chessable_train_error, 'val_error_cp': chessable_val_error}
    print(f"  chessable2023: Train={chessable_train_error:.2f} cp, Val={chessable_val_error:.2f} cp")
    del chessable_model_loaded

    # Empty GPU memory
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # Evaluate augmented CNN+MLP models
    print("\nEvaluating CNN models...")

    # Evaluate each config of CNN+MLP model
    for config in encoder_configs:
        encoder_model_name = config['model_name']
        embed_column_name = config['embed_column']
        embedding_dim = config['embedding_dim']

        # Load embedding lookup for this encoder
        embed_file = output_dir / f"{embed_column_name}_lookup.pkl"
        with open(embed_file, 'rb') as f:
            fen_to_embedding = pickle.load(f)

        # Create dataframes with embeddings for this encoder only
        train_df_with_embed = train_df.copy()
        val_df_with_embed = val_df.copy()
        train_df_with_embed[embed_column_name] = train_df_with_embed['fen'].map(fen_to_embedding)
        val_df_with_embed[embed_column_name] = val_df_with_embed['fen'].map(fen_to_embedding)

        # Evaluate each piece value predictor variant
        for num_hidden_layers in sorted(CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS.keys()):
            hidden_sizes = CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS[num_hidden_layers]
            dropout_rates = CNN_PIECEVAL_DROPOUT_RATES[num_hidden_layers]
            hidden_arch_str = '-'.join(map(str, hidden_sizes))
            full_model_name = f"{encoder_model_name}_pval_{hidden_arch_str}"

            # Load model (with graduated dropout)
            cnn_model_loaded = CNNPieceValuePredictor(
                embedding_dim=embedding_dim,
                hidden_sizes=hidden_sizes,
                dropout_rates=dropout_rates
            ).to(device)
            cnn_model_loaded.load_state_dict(torch.load(output_dir / f"{full_model_name}_model.pth"))

            # Evaluate
            cnn_train_error = evaluate_cnn_pieceval_model(
                cnn_model_loaded,
                train_df_with_embed,
                norm_params=norm_params,
                device=device,
                embed_column=embed_column_name
            )
            cnn_val_error = evaluate_cnn_pieceval_model(
                cnn_model_loaded,
                val_df_with_embed,
                norm_params=norm_params,
                device=device,
                embed_column=embed_column_name
            )

            evaluation_results[full_model_name] = {'train_error_cp': cnn_train_error, 'val_error_cp': cnn_val_error}

            print(f"  {full_model_name}: Train={cnn_train_error:.2f} cp, Val={cnn_val_error:.2f} cp")

            # Empty GPU memory
            del cnn_model_loaded
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        # Clean up this encoder's data before moving to next
        del train_df_with_embed, val_df_with_embed, fen_to_embedding
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # ========================================
    # Save Final Model Eval Results
    # ========================================
    print(f"\n{'='*80}")
    print("STEP 7: SAVING RESULTS")
    print(f"{'='*80}")

    results = {
        'dataset_info': {
            'training_file': TRAINING_PARQUET,
            'validation_file': VALIDATION_PARQUET,
            'training_rows': len(train_df),
            'validation_rows': len(val_df),
            'unique_positions_train': len(unique_fens),
            'normalization': norm_params
        },
        'optimizations': {
            'optimizer': 'AdamW',
            'weight_decay': CNN_PIECEVAL_CONFIG['weight_decay'],
            'loss_function': f'HuberLoss(delta={HUBER_DELTA})',
            'normalization': 'standardization (zero mean, unit variance)',
            'mlp_batchnorm': True,
            'graduated_dropout': True,
            'dropout_rates': {str(k): v for k, v in CNN_PIECEVAL_DROPOUT_RATES.items()},
            'game_level_split': 'recommended (via optimized_create_val_train_splits.py)'
        },
        'mlp_models': {
            'mlp1': mlp1_metadata,
            'mlp2': mlp2_metadata,
            'chessable2023': chessable2023_metadata
        },
        'cnn_models': cnn_models_metadata,
        'evaluation': evaluation_results
    }

    # Save to JSON
    metrics_file = output_dir / "all_models_metrics.json"
    with open(metrics_file, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"Saved metrics to {metrics_file}\n")

    # ========================================
    # PRINT FINAL SUMMARY
    # ========================================
    print(f"\n{'='*80}")
    print("TRAINING COMPLETE - MODEL PERFORMANCE SUMMARY (OPTIMIZED)")
    print(f"{'='*80}")
    print(f"\n{'Model':<50} {'Train MAE':>12} {'Val MAE':>12} {'Gap':>8}")
    print(f"{'-'*50} {'-'*12} {'-'*12} {'-'*8}")

    # MLP models
    print("\nMLP Baselines:")
    mlp_display_names = {
        'mlp1': 'MLP #1 (12-dim, 3 layers [128,64,32])',
        'mlp2': 'MLP #2 (14-dim, 3 layers [128,64,32])',
        'chessable2023': 'Chessable-Research-2023 (12-dim, 2 layers [64,32])'
    }
    for model_name, display_name in mlp_display_names.items():
        train_err = evaluation_results[model_name]['train_error_cp']
        val_err = evaluation_results[model_name]['val_error_cp']
        gap = val_err - train_err
        print(f"{display_name:<50} {train_err:>11.2f} cp {val_err:>11.2f} cp {gap:>+7.2f}")

    # CNN models
    print("\nCNN-based Models:")
    for embedding_dim in CNN_EMBEDDING_DIMS:
        for num_layers in CNN_LAYER_DEPTHS:
            for num_hidden_layers in sorted(CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS.keys()):
                hidden_sizes = CNN_PIECEVAL_HIDDEN_LAYER_VARIANTS[num_hidden_layers]
                hidden_arch_str = '-'.join(map(str, hidden_sizes))
                encoder_model_name = f"cnn_pos_{embedding_dim}d_{num_layers}layer"
                full_model_name = f"{encoder_model_name}_pval_{hidden_arch_str}"

                train_err = evaluation_results[full_model_name]['train_error_cp']
                val_err = evaluation_results[full_model_name]['val_error_cp']
                gap = val_err - train_err
                display_name = f"CNN pos {embedding_dim}d-{num_layers}layer, pval {hidden_arch_str}"
                print(f"{display_name:<50} {train_err:>11.2f} cp {val_err:>11.2f} cp {gap:>+7.2f}")

    # Sort all models by validation error
    print(f"\n{'='*80}")
    print("ALL MODELS SORTED BY VALIDATION ERROR (Best to Worst)")
    print(f"{'='*80}")
    print(f"\n{'Rank':<6} {'Model':<50} {'Val MAE':>12} {'Train-Val Gap':>14}")
    print(f"{'-'*6} {'-'*50} {'-'*12} {'-'*14}")

    sorted_models = sorted(evaluation_results.items(), key=lambda x: x[1]['val_error_cp'])
    for rank, (model_name, metrics) in enumerate(sorted_models, 1):
        # Create display name
        if model_name == 'mlp1':
            display = 'MLP #1 (12-dim, 3 layers)'
        elif model_name == 'mlp2':
            display = 'MLP #2 (14-dim, 3 layers)'
        elif model_name == 'chessable2023':
            display = 'Chessable-2023 (12-dim, 2 layers)'
        else:
            display = model_name

        val_err = metrics['val_error_cp']
        train_err = metrics['train_error_cp']
        gap = val_err - train_err
        print(f"{rank:<6} {display:<50} {val_err:>11.2f} cp {gap:>+13.2f} cp")

    # Find best model
    best_model = sorted_models[0]
    print(f"\n{'='*80}")
    print(f"BEST MODEL: {best_model[0]}")
    print(f"{'='*80}")
    print(f"  Training MAE: {best_model[1]['train_error_cp']:.2f} cp")
    print(f"  Validation MAE: {best_model[1]['val_error_cp']:.2f} cp")
    print(f"  Train-Val Gap: {best_model[1]['val_error_cp'] - best_model[1]['train_error_cp']:+.2f} cp")

    # Print final training confirmation and stats
    total_models_trained = 3 + total_models  # 3 MLPs + CNN models
    print(f"\n{'='*80}")
    print(f"All {total_models_trained} models trained and evaluated successfully!")
    print(f"  - 3 MLP baseline models")
    print(f"  - {total_models} CNN-based models")
    print(f"{'='*80}\n")

# main(main)
if __name__ == "__main__":
    main()